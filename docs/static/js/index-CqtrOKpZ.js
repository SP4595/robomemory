import{c as a,a as e,b as s,d as n,F as i,o as r,e as t}from"./@vue-PnvlrbKp.js";!function(){const a=document.createElement("link").relList;if(!(a&&a.supports&&a.supports("modulepreload"))){for(const a of document.querySelectorAll('link[rel="modulepreload"]'))e(a);new MutationObserver(a=>{for(const s of a)if("childList"===s.type)for(const a of s.addedNodes)"LINK"===a.tagName&&"modulepreload"===a.rel&&e(a)}).observe(document,{childList:!0,subtree:!0})}function e(a){if(a.ep)return;a.ep=!0;const e=function(a){const e={};return a.integrity&&(e.integrity=a.integrity),a.referrerPolicy&&(e.referrerPolicy=a.referrerPolicy),"use-credentials"===a.crossOrigin?e.credentials="include":"anonymous"===a.crossOrigin?e.credentials="omit":e.credentials="same-origin",e}(a);fetch(a.href,e)}}();t(((a,e)=>{const s=a.__vccOpts||a;for(const[n,i]of e)s[n]=i;return s})({},[["render",function(t,o){return r(),a(i,null,[o[0]||(o[0]=e("div",{class:"articleTitleContainer contentContainer"},[e("div",{class:"articleTitle"},[e("span",{class:"colorStress"},"RoboMemory:")]),e("div",{class:"articleTitle subTitle"}," A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems "),e("div",{class:"arthorNameLine"},[e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Mingcong Lei"),e("span",{class:"sup"},"1, 3, *"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Honghao Cai"),e("span",{class:"sup"},"1, *"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Zezhou Cui"),e("span",{class:"sup"},"1, 3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Liangchen Tan"),e("span",{class:"sup"},"4"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Junkun Hong"),e("span",{class:"sup"},"1"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Gehan Hu"),e("span",{class:"sup"},"1, 3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Shuangyu Zhu"),e("span",{class:"sup"},"1, 6"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Yimou Wu"),e("span",{class:"sup"},"3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Shaohan Jiang"),e("span",{class:"sup"},"1, 3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Ge Wang"),e("span",{class:"sup"},"1, 3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Yuyuan Yang"),e("span",{class:"sup"},"3"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Junyuan Tan"),e("span",{class:"sup"},"1"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Zhenglin Wan"),e("span",{class:"sup"},"5"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Zhen Li"),e("span",{class:"sup"},"1, 2"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Shuguang Cui"),e("span",{class:"sup"},"1, 2"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Yiming Zhao"),e("span",{class:"sup"},"1, 7, 8"),e("span",{class:"arthorName"},", ")]),e("div",{class:"arthorNameContainer"},[e("span",{class:"arthorName"},"Yatong Han"),e("span",{class:"sup"},"1, 8")])]),e("div",{class:"expression"},[e("div",{class:"expressionItem"},[e("span",{class:"sup"}," * "),e("span",{class:"expressionText"},"Equal Contribution")])]),e("div",{class:"university"},[e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 1 "),e("span",{class:"universityName"},"FNii-Shenzhen ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 2 "),e("span",{class:"universityName"},"SSE ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 3 "),e("span",{class:"universityName"},"The Chinese University of Hong Kong, Shenzhen ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 4 "),e("span",{class:"universityName"},"The University of Hong Kong ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 5 "),e("span",{class:"universityName"},"Nanyang Technological University ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 6 "),e("span",{class:"universityName"},"Harbin Institute of Technology, Shenzhen ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 7 "),e("span",{class:"universityName"},"Harbin Engineering University ")]),e("div",{class:"universityContainer"},[e("span",{class:"sup"}," 8 "),e("span",{class:"universityName"},"Infused Synapse AI ")])]),e("div",{class:"buttonGroup"},[e("button",{class:"button",onclick:"window.open('https://arxiv.org/abs/2508.01415')",type:"button"},[e("div",{class:"arxivIcon"}),n(" arXiv ")]),e("button",{class:"button unfinished",onclick:"window.alert('Code will be released soon!')",type:"button"},[e("div",{class:"gitHubIcon"}),n(" Code ")])])],-1)),o[1]||(o[1]=e("div",{class:"videoDisplayContainer contentContainer coverVideo"},[e("video",{muted:"",playsinline:"",loop:"",controls:"","disable-picture-in-picture":"true"},[e("source",{src:"/robomemory/static/mp4/RoboMemory_compressed-CG06VzUN.mp4",type:"video/mp4"})])],-1)),o[2]||(o[2]=s('<div class="articleMainBodyContainer contentContainer" data-v-cdede0e2><div class="contentMainTitle" data-v-cdede0e2>Abstract</div><div class="content" data-v-cdede0e2> Embodied agents face persistent challenges in real-world environments, including partial observability, limited spatial reasoning, and high-latency multi-memory integration. We present RoboMemory, a brain-inspired framework that unifies Spatial, Temporal, Episodic, and Semantic memory under a parallelized archi tecture for efficient long-horizon planning and interactive environmental learn ing. A dynamic spatial knowledge graph (KG) ensures scalable and consistent memory updates, while a closed-loop planner with a critic module supports adaptive decision-making in dynamic settings. Experiments on EmbodiedBench show that RoboMemory, built on Qwen2.5-VL-72B-Ins, improves average success rates by 25% over its baseline and exceeds the closed-source state-of-the-art (SOTA) Gemini-1.5-Pro by 3%. Real-world trials further confirm its capacity for cumulative learning, with performance improving across repeated tasks. These results highlight RoboMemory as a scalable foundation for memory-augmented embodied intelligence, bridging the gap between cognitive neuroscience and robotic autonomy. </div></div><div class="articleMainBodyContainer contentContainer" data-v-cdede0e2><div class="contentImg contentImg1" data-v-cdede0e2><img src="/robomemory/static/png/fig1_og-C72ilg2-.png" alt="image" data-v-cdede0e2><div class="introText" data-v-cdede0e2><span class="bold" data-v-cdede0e2>Figure 1:</span> The brain-inspired architecture of the RoboMemory resembles the biological nervous system. It maps biological neural components, enabling the agent to interact with diverse environments (real-world, Habitat, ALFRED) and robotic hardware for long-term planning and lifelong learning. </div></div></div><div class="articleMainBodyContainer contentContainer" data-v-cdede0e2><div class="contentImg contentImg" data-v-cdede0e2><img src="/robomemory/static/png/fig2-RaIZpvcZ.png" alt="image" data-v-cdede0e2><div class="introText" data-v-cdede0e2><span class="bold" data-v-cdede0e2>Figure 2: RoboMemory architecture. </span>(a) Left: Parallel Step Summarizer and Query Generator generate updates/queries for Comprehensive Embodied Memory. These memories enable Closed Loop Planning for tasks like “slice and pick up the apple”—the Planner generates plans, while the Critic and memories adjust decisions via feedback from visual inputs/results. (b) Right: Spatial memory maintains a relevance/similarity-updated KG, and Semantic/Episodic memory manages a Vector DB with analogous logic. Besides, Temporal memory is implemented as a linear FIFO buffer that stores step-wise summaries generated by the Step Summarizer. Together, S and Q provide a swift, text-based interface between raw sensory data and provide basic information in each iteration for RoboMemory’s Comprehensive Embodied Memory System. </div></div></div>',3))],64)}],["__scopeId","data-v-cdede0e2"]])).mount("#app");
